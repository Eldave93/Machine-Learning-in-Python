{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# This line will add a button to toggle visibility of code blocks,\n",
    "# for use with the HTML export version\n",
    "from IPython.core.display import HTML\n",
    "HTML('''<button style=\"margin:0 auto; display: block;\" onclick=\"jQuery('.code_cell .input_area').toggle();\n",
    "    jQuery('.prompt').toggle();\">Toggle code</button>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./Images/UoE_Horizontal_Logo_282_v1_160215.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "# Week 8 - Support Vector Machines\n",
    "__Dr. David Elliott__\n",
    "\n",
    "4. [Support Vector Classifier (SVC)](#svc)\n",
    "\n",
    "5. [Support Vector Machine (SVM)](#svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Common Notation__\n",
    "\n",
    "- $\\mathbf{X}$ is a matrix containing all the feature values of all the observations\n",
    "- $n$ is the number of observations in the dataset\n",
    "- $\\mathbf{x}_i$ is a vector of all the feature values (except the label) of the $i$th instance in the dataset.\n",
    "- $y_i$ is the label (desired model output) of the $i$th instance in the dataset.\n",
    "- $p$ is the number of features in the dataset\n",
    "- $\\mathbf{x}_j$ is a vector of all the observations values of the $j$th feature in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "\n",
    "We can't always perfectly separate the data with a $p âˆ’ 1$ dimensional hyperplane. To overcome this problem we could either:\n",
    "- Tweak the constraints on the hyperplane to allow some points to be misclassified (_soft margin_),\n",
    "- Transform the data to be separable by a hyperplane in another space (_kernel method_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os # locating directories\n",
    "\n",
    "import numpy as np   # Arrays\n",
    "import pandas as pd  # DataFrames\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['animation.embed_limit'] = 30000000.0\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.datasets import load_iris           # for the Iris data\n",
    "from IPython.display import Image                # displaying .png images\n",
    "from sklearn.svm import SVC, LinearSVC           # SVM\n",
    "from mpl_toolkits.mplot3d import Axes3D          # 3d plots\n",
    "from sklearn.preprocessing import StandardScaler # scaling features\n",
    "from sklearn.preprocessing import LabelEncoder   # binary encoding\n",
    "from sklearn.pipeline import Pipeline            # combining classifier steps\n",
    "from sklearn.preprocessing import PolynomialFeatures # make PolynomialFeatures\n",
    "from sklearn.datasets import make_classification, make_moons  # make example data\n",
    "\n",
    "import itertools\n",
    "from time import time\n",
    "import joblib # saving models\n",
    "import warnings # prevent warnings\n",
    "\n",
    "# colours for print()\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "    \n",
    "image_dir = os.path.join(os.getcwd(),\"Images\")\n",
    "# Initial fig number\n",
    "fig_num=15\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "# golden ratio for figures ()\n",
    "gr = 1.618\n",
    "\n",
    "height_pix = 500\n",
    "width_pix = height_pix*gr\n",
    "\n",
    "height_inch = 4\n",
    "width_inch = height_inch*gr\n",
    "\n",
    "# if trying to make PDF\n",
    "PDF=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "iris = load_iris(as_frame=True)  # data stored in a `sklearn.utils.Bunch`\n",
    "iris_df = iris['data']           # get features DataFrame\n",
    "target = iris['target']          # get target Series\n",
    "# get the labels of flowers capitalised for visualisation\n",
    "target_names = list(map(lambda s: s.capitalize(), iris['target_names']))\n",
    "\n",
    "# create a dictionary with the original labels decoded (inverse of LabelEncoder)\n",
    "decode_label = dict(zip(range(3), target_names))\n",
    "\n",
    "# make a label encoder to use later if needed\n",
    "le = LabelEncoder().fit(target_names)\n",
    "# add the target labels to df for visualisation purposes\n",
    "iris_vis = pd.concat([iris_df, target],axis=1)\n",
    "# turn the ints to labels\n",
    "iris_vis[\"target\"] = iris_vis[\"target\"].replace(decode_label)\n",
    "# Capitalize column names for plotting\n",
    "iris_vis.columns = [x.capitalize() for x in list(iris_vis.columns)]\n",
    "# reduce the data for example\n",
    "X_AX_LABEL = \"Petal length (cm)\"\n",
    "Y_AX_LABEL = \"Petal width (cm)\"\n",
    "REMOVE = \"Virginica\"\n",
    "\n",
    "iris_reduced = iris_vis[[X_AX_LABEL, Y_AX_LABEL, \"Target\"]]\n",
    "iris_reduced = iris_reduced[iris_reduced.Target != REMOVE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Centered figures in the notebook and presentation\n",
    "# ...was a real pain to find this:\n",
    "# https://gist.githubusercontent.com/maxalbert/800b9f06c7b2dd365ea5\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import urllib\n",
    "import base64\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "def fig2str(fig, format='svg'):\n",
    "    \"\"\"\n",
    "    Return a string containing the raw data of the matplotlib figure in the given format.\n",
    "\n",
    "    \"\"\"\n",
    "    assert isinstance(fig, matplotlib.figure.Figure)\n",
    "    imgdata = BytesIO()\n",
    "    fig.savefig(imgdata, format=format, bbox_inches='tight')\n",
    "    imgdata.seek(0)  # rewind the data\n",
    "    output = imgdata.getvalue()\n",
    "    if format == 'svg':\n",
    "        return output\n",
    "    else:\n",
    "        return urllib.parse.quote(base64.b64encode(output))\n",
    "\n",
    "class MatplotlibFigure(object):\n",
    "    \"\"\"\n",
    "    Thin wrapper around a matplotlib figure which provides a custom\n",
    "    HTML representation that allows tweaking the appearance\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, fig, centered=False):\n",
    "        assert isinstance(fig, matplotlib.figure.Figure)\n",
    "        self.centered = centered\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        img_str_png = fig2str(fig, format='png')\n",
    "        uri = 'data:image/png;base64,' + img_str_png\n",
    "        html_repr = \"<img src='{}'>\".format(uri)\n",
    "        if self.centered:\n",
    "            html_repr = \"<center>\" + html_repr + \"</center>\"\n",
    "        return html_repr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1.4. Support Vector Classifier (SVC) <a id='svc'></a>\n",
    "\n",
    "SVC's are a generalisation and extension of the maximal margin classifier so it can be applied to a broader range of cases$^1$.\n",
    "\n",
    "In practice they are more robust to individual observations and better classify most training observations than the Maximal Margin Classifier. This is because they take the approach it is better to missclassify some training examples in order to do a better job classifying the rest.\n",
    "\n",
    "This is called a *soft margin* as it allows some violations by the training data by a small subset of training observation, not only on the wrong side of the margin, but wrong side of the hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- _\"Developed in the computer science community in the 1990s\"_$^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def svc_decision_boundary(clf, xmin=0, xmax=5.5, highlight=True, axes_limit = [0, 5.5, 0, 2]):\n",
    "    w = clf.coef_[0]\n",
    "    b = clf.intercept_[0]\n",
    "\n",
    "    # At the decision boundary, w0*x0 + w1*x1 + b = 0\n",
    "    # => x1 = -w0/w1 * x0 - b/w1\n",
    "    x0 = np.linspace(xmin, xmax, 200)\n",
    "    decision_boundary = -w[0]/w[1] * x0 - b/w[1]\n",
    "\n",
    "    margin = 1/w[1]\n",
    "    gutter_up = decision_boundary + margin\n",
    "    gutter_down = decision_boundary - margin\n",
    "\n",
    "    svs = clf.support_vectors_\n",
    "    if highlight:\n",
    "        g = sns.scatterplot(x = svs[:, 0], y = svs[:, 1], s=180, facecolors='#FFAAAA')\n",
    "    plt.plot(x0, decision_boundary, \"g-\", linewidth=2)\n",
    "    plt.plot(x0, gutter_up, \"r--\", linewidth=2)\n",
    "    plt.plot(x0, gutter_down, \"r--\", linewidth=2)\n",
    "    \n",
    "    plt.axis(axes_limit)\n",
    "\n",
    "\n",
    "def soft_margin(title, hyperplane=False):\n",
    "    virgin_versi = iris_vis[[\"Petal length (cm)\", \"Petal width (cm)\", \"Target\"]]\n",
    "    virgin_versi = virgin_versi[virgin_versi.Target != \"Setosa\"]\n",
    "\n",
    "    X = virgin_versi[[\"Petal length (cm)\", \"Petal width (cm)\"]].values\n",
    "    y = virgin_versi[[\"Target\"]].replace({'Versicolor':0, 'Virginica':1}).values.ravel()\n",
    "    \n",
    "    if hyperplane:\n",
    "        svm_clf = SVC(kernel=\"linear\", C=100)\n",
    "        svm_clf.fit(X, y)\n",
    "\n",
    "        svc_decision_boundary(svm_clf, 2.9, 7)\n",
    "    labels = virgin_versi[[\"Target\"]].values.ravel()\n",
    "    sns.scatterplot(x = X[:,0], y = X[:,1], hue=labels, style = labels)\n",
    "    plt.axis([2.9, 7, 0.9, 2.75])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Petal Length (cm)\")\n",
    "    plt.ylabel(\"Petal Width (cm)\")\n",
    "    \n",
    "fig_num+=1\n",
    "fig = plt.figure(figsize=(width_inch, height_inch))\n",
    "soft_margin(\"Figure %d: No Exact Linear Separating Hyperplane\"%fig_num)\n",
    "if PDF:\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.close()\n",
    "    display(MatplotlibFigure(fig, centered=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig_num+=1\n",
    "fig = plt.figure(figsize=(width_inch, height_inch))\n",
    "soft_margin(\"Figure %d: Soft Margin Hyperplane\"%fig_num, hyperplane=True)\n",
    "plt.savefig(os.path.join(image_dir,\"Soft_Margin_Hyperplane.png\"))\n",
    "if PDF:\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.close()\n",
    "    display(MatplotlibFigure(fig, centered=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We want to relax the following constraints when necessary:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^{\\mathrm T}\\mathbf{x}_i + b \\geq 1 \\text{ for } y_i = 1, \\\\\n",
    "\\mathbf{w}^{\\mathrm T}\\mathbf{x}_i + b \\leq -1 \\text{ for } y_i = -1\n",
    "$$\n",
    "\n",
    "This can be done by introducing positive slack variables $\\xi_i, i = 1, \\ldots, n$ in the constraints$^{5,6,10}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^{\\mathrm T}\\mathbf{x}_i + b \\geq 1 - \\xi_i \\quad \\text{if} \\quad y_i = 1, \\\\\n",
    "\\mathbf{w}^{\\mathrm T}\\mathbf{x}_i + b \\leq -1 + \\xi_i \\quad \\text{if} \\quad y_i = -1, \\\\\n",
    "\\xi_i \\geq 0 \\quad \\forall_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "\n",
    "- Slack variable $\\xi_1,..., \\xi_n$ allow individual observations to be on the wrong side of the margin or hyperplane.\n",
    "- $\\sum_i\\xi_i$ is an upper bound on the number of training errors.\n",
    "- $\\xi_i$ tells us where the $i$th observation is located relative to the hyperplane; $\\xi_i = 0$ being on the correct side of the margin, $\\xi_i > 0$ being on the wrong side of the margin, and $\\xi_i > 1$ on the wrong side of the hyperplane.\n",
    "- $\\xi_1 = ... = \\xi_n = 0$ is the maximal margin hyperplane optimisation.\n",
    "- Test observations are classified as before, $f(x^*) = \\beta_0 + \\beta_1x^*_1 + ... + \\beta_px^*_p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tuning Parameter (C)\n",
    "\n",
    "To ensure there is a penelty, $C$, for relaxing the constraint, we can change our objective function to be minimised from $\\frac{1}{2}||\\mathbf{w}||^2$ to,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Math\n",
    "# pdf's are not a fan of \\begin{align}\n",
    "if PDF:\n",
    "    display(Math(\n",
    "    r\"\"\"\n",
    "    {\\text{minimise} \\atop \\mathbf{w}, b, \\xi } \\quad \\frac{1}{2}||\\mathbf{w}||^2+C\\sum\\limits_{i=1}^n\\xi_i\n",
    "    \"\"\"))\n",
    "\n",
    "else:\n",
    "    display(Math(\n",
    "    r\"\"\"\n",
    "    \\begin{align}\n",
    "    {\\text{minimise}  \\atop \\mathbf{w}, b, \\xi } & \\quad \\frac{1}{2}||\\mathbf{w}||^2+C\\sum\\limits_{i=1}^n\\xi_i, \\\\ \n",
    "    \\text{subject to}                            & \\quad y_i(\\mathbf{w}^{\\mathrm T}\\mathbf{x}_i+b) \\geq 1-\\xi_i, \\quad \\xi_i \\geq 0, \\quad \\forall_i.\n",
    "    \\end{align}\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$C$ is a tuning parameter that controls the bias-variance trade-off$^1$. \n",
    "\n",
    "The strength of the regularization is inversely proportional to $C$, meaning a large $C$ has a larger error penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from shutil import copyfile\n",
    "\n",
    "# where the HTML template is located\n",
    "dst = os.path.join(sys.prefix, 'lib', 'site-packages', 'nbconvert', 'templates', \"classic.tplx\")\n",
    "\n",
    "# If its not located where it should be\n",
    "if not os.path.exists(dst):\n",
    "    # uses a nb_pdf_template\n",
    "    curr_path = os.path.join(os.getcwd(),\"..\", \"Extra\", \"classic.tplx\")\n",
    "    # copy where it is meant to be\n",
    "    copyfile(curr_path, dst)\n",
    "\n",
    "if not PDF:\n",
    "    # Create HTML notes document (preferred)\n",
    "    !jupyter nbconvert 2_Support_Vector_Machines.ipynb \\\n",
    "        --to html \\\n",
    "        --output-dir . \\\n",
    "        --template classic\n",
    "    !jupyter nbconvert 2_Support_Vector_Machines.ipynb \\\n",
    "        --to slides \\\n",
    "        --output-dir . \\\n",
    "        --TemplateExporter.exclude_input=True \\\n",
    "        --TemplateExporter.exclude_output_prompt=True \\\n",
    "        --SlidesExporter.reveal_scroll=True\n",
    "else:\n",
    "    # Create pdf notes document (issues)\n",
    "    !jupyter nbconvert 2_Support_Vector_Machines-Copy1.ipynb \\\n",
    "        --to pdf \\\n",
    "        --output-dir . \\\n",
    "        --TemplateExporter.exclude_input=True \\\n",
    "        --TemplateExporter.exclude_output_prompt=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "authorship_tag": "ABX9TyMNuZgSJ2BiDt5YMpOB66EK",
   "collapsed_sections": [],
   "name": "Clustering.ipynb",
   "provenance": []
  },
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "rise": {}
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
