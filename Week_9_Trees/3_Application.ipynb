{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Application\n",
    "\n",
    "__TODO__\n",
    "- make this section still focused on teh theory but more on details specifc to applying it to data (e.g. imballanced datasets)\n",
    "- compare models together to demonstrate pros and cons\n",
    "- add stuff from pg. 552 in ML prob perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and Cons\n",
    "\n",
    "__Pros__\n",
    "- Easy to explain\n",
    "    - Trees can be displayed graphically in an interpretable mannor.\n",
    "- Inherently multiclass\n",
    "- Can handle different types of predictors*.\n",
    "    - Independent of feature scaling\n",
    "\n",
    "__Cons__\n",
    "\n",
    "- Comparatively low predictive accuracy\n",
    "    - Easy to overfit\n",
    "    - Require pruning\n",
    "\n",
    "- High variance\n",
    "    - A small change in the data can cause a large change in the estimated tree.\n",
    "    - Model affected by the rotation of the data\n",
    "\n",
    "---\n",
    "James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. An introduction to statistical learning. Vol. 112. New York: springer, 2013.\n",
    "\n",
    "https://github.com/rasbt/stat479-machine-learning-fs19/blob/master/06_trees/06-trees__notes.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Some advantages of decision trees are:\n",
    ">\n",
    "> Simple to understand and to interpret. Trees can be visualised.\n",
    ">\n",
    "> Requires little data preparation. Other techniques often require data normalisation, dummy variables need to be created and blank values to be removed. Note however that this module does not support missing values.\n",
    ">\n",
    "> The cost of using the tree (i.e., predicting data) is logarithmic in the number of data points used to train the tree.\n",
    ">\n",
    "> Able to handle both numerical and categorical data. However scikit-learn implementation does not support categorical variables for now. Other techniques are usually specialised in analysing datasets that have only one type of variable. See algorithms for more information.\n",
    ">\n",
    "> Able to handle multi-output problems.\n",
    ">\n",
    "> Uses a white box model. If a given situation is observable in a model, the explanation for the condition is easily explained by boolean logic. By contrast, in a black box model (e.g., in an artificial neural network), results may be more difficult to interpret.\n",
    ">\n",
    "> Possible to validate a model using statistical tests. That makes it possible to account for the reliability of the model.\n",
    ">\n",
    "> Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.\n",
    ">\n",
    "> The disadvantages of decision trees include:\n",
    ">\n",
    "> Decision-tree learners can create over-complex trees that do not generalise the data well. This is called overfitting. Mechanisms such as pruning, setting the minimum number of samples required at a leaf node or setting the maximum depth of the tree are necessary to avoid this problem.\n",
    ">\n",
    "> Decision trees can be unstable because small variations in the data might result in a completely different tree being generated. This problem is mitigated by using decision trees within an ensemble.\n",
    ">\n",
    "> Predictions of decision trees are neither smooth nor continuous, but piecewise constant approximations as seen in the above figure. Therefore, they are not good at extrapolation.\n",
    ">\n",
    "> The problem of learning an optimal decision tree is known to be NP-complete under several aspects of optimality and even for simple concepts. Consequently, practical decision-tree learning algorithms are based on heuristic algorithms such as the greedy algorithm where locally optimal decisions are made at each node. Such algorithms cannot guarantee to return the globally optimal decision tree. This can be mitigated by training multiple trees in an ensemble learner, where the features and samples are randomly sampled with replacement.\n",
    ">\n",
    ">There are concepts that are hard to learn because decision trees do not express them easily, such as XOR, parity or multiplexer problems.\n",
    ">\n",
    "> Decision tree learners create biased trees if some classes dominate. It is therefore recommended to balance the dataset prior to fitting with the decision tree.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTES__\n",
    "\n",
    "- Decision trees potentially more mirror human decision-making than the regression and classification approaches previously discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (+) Easy to explain\n",
    "\n",
    "As well as being able to plot them in a straight forward manner, decision trees allow us assess the _importance_ of each feature for classifying the data.\n",
    "\n",
    "The importance (or Gini importance) of a feature is the normalized total reduction of the criterion (e.g. Gini) brought by that feature.\n",
    "\n",
    "---\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "__Notes__\n",
    "- Lets fit all the penguins on the full data (without categories) and see what features are used to split the data and where they are in the tree. \n",
    "- For bagging regression trees we can use the RSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_g = DecisionTreeClassifier(criterion='gini',\n",
    "                               random_state=42)\n",
    "#DT_g.fit(datasets['bin']['X'], datasets['bin']['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_feat_import(DT, X, y, feat_names, class_names, title):\n",
    "\n",
    "    DT.fit(X, y)\n",
    "    # get the importances for the features\n",
    "    importances = DT.feature_importances_\n",
    "\n",
    "    importances_series = pd.Series(importances,index=feat_names).sort_values(ascending = False)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows = 2, figsize=(8,8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    with plt.style.context(\"classic\"):\n",
    "        plt.sca(axes[0])\n",
    "        tp = tree.plot_tree(DT,\n",
    "                       feature_names=feat_names, \n",
    "                       class_names=class_names,\n",
    "                       filled = True)\n",
    "    \n",
    "    plt.sca(axes[1])\n",
    "    # plot the important features\n",
    "    importances_series.plot.barh(legend =False, grid=False)\n",
    "    plt.title(title)\n",
    "\n",
    "    #plt.xticks(rotation=45,ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #plt.savefig('forest_importances.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # summarize feature importance\n",
    "    for i,v in enumerate(importances):\n",
    "        print(color.BOLD+feat_names[i]+color.END+\": %.3f\" % (v))\n",
    "\n",
    "    print(color.BOLD+\"total: \"+color.END + str(round(sum(importances),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_feat_import(DT_g, datasets['bin']['X'], datasets['bin']['y'], \n",
    "                 datasets['bin']['feats'],datasets['bin']['class'],\n",
    "                 'Feature Importances for Classifying Adelie and Gentoo Penguins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DTREEVIS:\n",
    "    viz = dtreeviz(DT_g, datasets['bin']['X'], datasets['bin']['y'], \n",
    "                   feature_names=datasets['bin']['feats'],\n",
    "                   class_names=datasets['bin']['class'],\n",
    "                   orientation ='LR', \n",
    "                   colors = col_dict, # doesnt seem to do much..\n",
    "                   scale=2.0\n",
    "                  )\n",
    "    display(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (+) Inherently multiclass\n",
    "Tree-based classifiers are inherently multiclass...\n",
    "\n",
    "__[Insert about multiclass]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_g.fit(datasets['multi']['X'], datasets['multi']['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "names = [\"Sex\", \"Length\", \"Diameter\", \"Height\", \"Whole weight\", \n",
    "         \"Shucked weight\", \"Viscera weight\", \"Shell weight\", \"Rings\"]\n",
    "\n",
    "df = pd.read_csv(\"abalone_data.csv\", names=names)\n",
    "y_labels = df[\"Sex\"]\n",
    "X = df.drop(\"Sex\", axis=1)\n",
    "\n",
    "# create a dictionary with the our int labels\n",
    "labels_multi = dict(zip(y_labels.unique(), range(3)))\n",
    "\n",
    "# make a binary version - infants vs. adults\n",
    "labels_bin = labels_multi.copy()\n",
    "labels_bin['F'] = 0; labels_bin['I'] = 1\n",
    "\n",
    "# replace the labels so they are now binary\n",
    "y_bin = y_labels.replace(labels_bin)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y_bin.values, test_size = 0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,5))\n",
    "with plt.style.context(\"classic\"):\n",
    "    tree.plot_tree(DT_g,\n",
    "                   feature_names=datasets['multi']['feats'], \n",
    "                   class_names=datasets['multi']['class'], \n",
    "                   filled = True)\n",
    "    plt.show()\n",
    "print(datasets['multi']['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extra__\n",
    "\n",
    "Unsurprisingly, more features are needed to separate out the multi-class problem than in the binary class as can be seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_feat_import(DT_g, datasets['multi']['X'], datasets['multi']['y'], \n",
    "                 datasets['multi']['feats'], \n",
    "                 'Feature Importances for Classifying Adelie, Gentoo, and Chinstrap Penguins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Categorical Features and Sklearn\n",
    "\n",
    "You may also be wondering: where are my previous data visualisations of the categorical data before this? Well Sklearn's CART decision trees currently _\"does not support categorical variables\"_. This means:\n",
    "\n",
    "- Do not use `Label Encoding` if your categorical data is __not ordinal__ with `DecisionTreeClassifier()`, you'll end up with splits that do not make sense, as the data will be treat as numeric<sup>Web1</sup>.\n",
    "\n",
    "- Using a `OneHotEncoder` is the only current valid way with sklearn, allowing arbitrary splits not dependent on the label ordering, but is computationally expensive and it can deteriorate the performance of decision trees as it leads to sparse features, which can mess up feature importance<sup>Web1</sup>.\n",
    "\n",
    "__Solution__\n",
    "\n",
    "Currently the best way of handling categorical features is to use `catboost`. `catboost` is a boosting classifier as we discuss later, which can handle categorical inputs. If we want a tree then we can do something like the example below. However, while making these materials I haven't used `catboost` much so I'm still trying to figure out how to understand the categorical splits using this package - so I'll have to leave you to do your own digging to understand the tree below.\n",
    "\n",
    "---\n",
    "Web1. https://stackoverflow.com/questions/38108832/passing-categorical-data-to-sklearn-decision-tree\n",
    "Web2. https://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.metrics import accuracy_score\n",
    "test = penguins_rm\n",
    "X = test.drop('species', axis=1)[[\"sex\", \"island\"]]\n",
    "y = test['species']\n",
    "\n",
    "categorical_features_indices = np.where(X.dtypes != np.float)[0]\n",
    "\n",
    "pool = Pool(X, y, cat_features=categorical_features_indices, feature_names=list(X.columns))\n",
    "\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    custom_loss=['Accuracy'],\n",
    "    random_seed=42,\n",
    "    logging_level='Info',\n",
    "    iterations = 1,\n",
    "    max_depth=2,\n",
    "    max_ctr_complexity = 0,\n",
    ")\n",
    "\n",
    "model.fit(pool,\n",
    ")\n",
    "\n",
    "plot = model.plot_tree(tree_idx=0, pool = pool)\n",
    "\n",
    "display(plot)\n",
    "\n",
    "print(\"Leaf 1 prediction: \" + str(np.argmax([0.830,-0.415, -0.415])))\n",
    "print(\"Leaf 2 prediction: \" + str(np.argmax([0,0,0])))\n",
    "print(\"Leaf 3 prediction: \" + str(np.argmax([0.169, 0.255,-0.424])))\n",
    "print(\"Leaf 4 prediction: \" + str(np.argmax([-0.088, -0.2473,0.561])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (-) High variance\n",
    "\n",
    "__TODO__\n",
    "- more demonstration of this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rotation of the Data\n",
    "As can be seen by the descision boundary, a decision tree is quite boxy. Furthermore, how the model makes a decision boundary is going to be affected by the rotation of the data (as DTs create straight lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_tree(DT_g1, datasets['blbd']['X'], datasets['blbd']['y'], datasets['blbd']['feats'], \n",
    "             datasets['blbd']['class'], [[37, 22],[51.5, 22]], r_labels, tp_labels)\n",
    "regions_tree(DT_g, datasets['blbd']['X'], datasets['blbd']['y'], datasets['blbd']['feats'], \n",
    "             datasets['blbd']['class'], [[57.5, 19.5],[57.5, 14.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is a highly non-linear and complex relationship between the features and the response then decision trees may outperform classical approaches.\n",
    "\n",
    "However if the relationship between the features and the response is well approximated by a linear model, then an approach such as linear regression will likely work well.\n",
    "\n",
    "---\n",
    "James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. An introduction to statistical learning. Vol. 112. New York: springer, 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notes__\n",
    "\n",
    "- Linear regression assumes a model of the form $f(X)=\\beta 0+\\sum_{j=1}^p X_j\\beta_j$,\n",
    "\n",
    "- Regression trees assume a model of the form $f(X)=\\sum_{m=1}^Mc_m\\cdot1_{(X\\in R_m)}$, where $R_1, …, R_M$ represent a partition of feature space. \n",
    "\n",
    "- The relative performances of tree-based and classical approaches can be assessed by estimating the test error, using either cross-validation or the validation set approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(os.path.join(\"fig_8-7.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forests\n",
    "\n",
    "relatively good performance “out of the box” and ease of use (not much tuning required to get good results) https://github.com/rasbt/stat451-machine-learning-fs20/blob/master/L07/07-ensembles__notes.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at how a descion boundary created by a bagged tree could generalise better than a single tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_search(model, params, X, y, save_path, n_iter=60, random_state=42, overwrite=False):\n",
    "    if os.path.exists(save_path) and overwrite==False:\n",
    "        #load the model\n",
    "        models = joblib.load(save_path)\n",
    "    else:\n",
    "        # check all param inputs are lists\n",
    "        if all(type(x)==list for x in params.values()):\n",
    "            search_type = \"Gridsearch\"\n",
    "            models = GridSearchCV(model, param_grid=params)\n",
    "            n_iter = len(list(itertools.product(*list(iter(params.values())))))\n",
    "        else:\n",
    "            search_type = \"Randomsearch\"\n",
    "            models = RandomizedSearchCV(model, param_distributions=params,\n",
    "                                        n_iter=n_iter, random_state=random_state)\n",
    "        \n",
    "        start = time()\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            models.fit(X, y)\n",
    "        \n",
    "        print(search_type + \" took %.2f seconds for %d candidates\" % ((time() - start), n_iter))\n",
    "        joblib.dump(models, save_path)\n",
    "    \n",
    "    return models\n",
    "\n",
    "cancer_features = ['mean radius','mean smoothness']\n",
    "# specify parameters and distributions to sample from\n",
    "param_grid = {\"min_samples_leaf\":list(range(1,15))}\n",
    "\n",
    "lsamples_gs = hyper_search(DT, param_grid, X[cancer_features].values, y,\n",
    "                           os.path.join(os.getcwd(), \"Models\", \"lsamples_gs_object.pkl\"))\n",
    "\n",
    "pd.DataFrame(lsamples_gs.cv_results_).sort_values(\"rank_test_score\")[[\"param_min_samples_leaf\", \"mean_test_score\", \"std_test_score\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "param_grid = {\"n_estimators\":range(2,1000),\n",
    "              \"max_samples\":uniform(0.05, 1.)}\n",
    "\n",
    "rf_gs = hyper_search(RF, param_grid, X[cancer_features].values, y,\n",
    "                     os.path.join(os.getcwd(), \"Models\", \"rf_gs_object.pkl\"), \n",
    "                     n_iter=15, random_state=1, overwrite=False)\n",
    "\n",
    "pd.DataFrame(rf_gs.cv_results_).sort_values(\"rank_test_score\")[[\"param_n_estimators\", \"param_max_samples\", \"mean_test_score\", \"std_test_score\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dict = {'Tree':lsamples_gs.best_estimator_, 'Forest':rf_gs.best_estimator_}\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "for i, classifier_name in enumerate(tree_dict):\n",
    "    plt.sca(axes[i])\n",
    "\n",
    "    plot_decision_regions(X[cancer_features].values, y.values,\n",
    "                          clf = tree_dict[classifier_name])\n",
    "\n",
    "    plt.xlabel(cancer_features[0]) \n",
    "    plt.ylabel(cancer_features[1])\n",
    "\n",
    "    plt.title(classifier_name)\n",
    "    plt.ylim([0.05,0.18])\n",
    "    plt.xlim([10,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Dimension Reduction\n",
    "#### Model Stacking\n",
    "A method growing in popularity is to use model stacking, where the input to one model is the output of another. This allows for nonlinearities to be captured in the first model, and the potential to use a simple linear model as the last layer. Deep learning is an example of model stacking as, often neural networks are layered on top of one another, to optimize both the features and the classifier simultaneously<sup>1</sup>.\n",
    "\n",
    "---\n",
    "\n",
    "1. Zheng, A., & Casari, A. (2018). Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists. \" O'Reilly Media, Inc.\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Feature Importances\n",
    "\n",
    "An example of model stacking is to use the output of a decision tree–type model as input to a linear classifier. We can gain the importance for each feature by getting the average impurity decrease computed from all decision trees in the forest without regarding the linear separability of the classes. However, if features are highly correlated, one feature may be ranked highly while the information of the others not being fully captured<sup>1</sup>. \n",
    "\n",
    "---\n",
    "\n",
    "1. Raschka, Sebastian, and Vahid Mirjalili. Python Machine Learning, 2nd Ed. Packt Publishing, 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Rather than manually setting a theshold like we have done (looking at the top 30) we can put it in a pipeline and use the SelectFromModel function from Scikit-learn. Using this we can still provide both a numeric theshold or we could use a heuristic such as the mean and median<sup>1</sup>.\n",
    "\n",
    "---\n",
    "\n",
    "1. http://scikit-learn.org/stable/modules/feature_selection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[4mSVM\u001b[0m\n",
      "CV accuracy: 0.906 +/- 0.039\n",
      "\u001b[1m\u001b[4mForest SVM\u001b[0m\n",
      "CV accuracy: 0.986 +/- 0.012\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm = SVC(kernel='rbf', random_state=42, class_weight = 'balanced')\n",
    "rf = RandomForestClassifier(criterion='gini',\n",
    "                            n_estimators=100,\n",
    "                            max_features = 'sqrt',\n",
    "                            random_state=42,\n",
    "                            class_weight = 'balanced',\n",
    "                            n_jobs=-1)\n",
    "\n",
    "rf_svm = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(rf, threshold = 'mean')),\n",
    "  ('classification', svm)\n",
    "])\n",
    "\n",
    "svm_dict = {'SVM':svm, 'Forest SVM':rf_svm}\n",
    "\n",
    "for classifier_name in svm_dict:\n",
    "    scores = cross_val_score(estimator=svm_dict[classifier_name], \n",
    "                             X=X_train, \n",
    "                             y=y_train, \n",
    "                             scoring = 'accuracy',\n",
    "                             cv=StratifiedKFold(),\n",
    "                             n_jobs=-1)\n",
    "\n",
    "    print(color.BOLD+color.UNDERLINE+classifier_name+color.END)\n",
    "    #print('CV accuracy scores: %s' % scores)\n",
    "    print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Importance\n",
    "\n",
    "_\"impurity-based feature importances can be misleading for high cardinality features (many unique values). See `sklearn.inspection.permutation_importance` as an alternative\"_ https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "- _\"The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled<sup>9</sup>. This procedure breaks the relationship between the feature and the target, thus the drop in the model score is indicative of how much the model depends on the feature. This technique benefits from being model agnostic and can be calculated many times with different permutations of the feature.\"_ https://scikit-learn.org/stable/modules/permutation_importance.html\n",
    "- _\"Its validation performance, measured via the score, is significantly larger than the chance level. This makes it possible to use the permutation_importance function to probe which features are most predictive\"_ https://scikit-learn.org/stable/modules/permutation_importance.html\n",
    "-_\"Using a held-out set makes it possible to highlight which features contribute the most to the generalization power of the inspected model. Features that are important on the training set but not on the held-out set might cause the model to overfit.\"_ https://scikit-learn.org/stable/modules/permutation_importance.html\n",
    "---\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTES__\n",
    "- _\"Warning: Features that are deemed of low importance for a bad model (low cross-validation score) could be very important for a good model. Therefore it is always important to evaluate the predictive power of a model using a held-out set (or better with cross-validation) prior to computing importances. Permutation importance does not reflect to the intrinsic predictive value of a feature by itself but how important this feature is for a particular model.\"_ https://scikit-learn.org/stable/modules/permutation_importance.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Imballanced Data\n",
    "It is also worth noting we have been dealing with the class imballance found in this data by using `class_weight = 'balanced'` to assign more importance to getting ictal data predictions correct. We can however also undersample using a ballanced random forest. Generally what performs better depends on the amount of data you are training on. If small then class wight will be better (as seen below), but if you have very large datasets, then undersampling will likely work better.\n",
    "\n",
    "__NOTE__\n",
    "- note sure this imballance is going to do much, use abalone_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 113, 1: 99})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[4mRandom Forest\u001b[0m\n",
      "CV accuracy: 0.995 +/- 0.010\n",
      "\u001b[1m\u001b[4mBalanced Random Forest\u001b[0m\n",
      "CV accuracy: 0.995 +/- 0.010\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "bal_f = BalancedRandomForestClassifier(criterion='gini',\n",
    "                                       n_estimators=1000,\n",
    "                                       max_features = 'sqrt',\n",
    "                                       random_state=42,\n",
    "                                       n_jobs=-1)\n",
    "\n",
    "rf_dict = {'Random Forest':rf, 'Balanced Random Forest':bal_f}\n",
    "\n",
    "for classifier_name in rf_dict:\n",
    "    scores = cross_val_score(estimator=rf_dict[classifier_name], \n",
    "                             X=X_train, \n",
    "                             y=y_train, \n",
    "                             scoring = 'accuracy',\n",
    "                             cv=StratifiedKFold(),\n",
    "                             n_jobs=-1)\n",
    "\n",
    "    print(color.BOLD+color.UNDERLINE+classifier_name+color.END)\n",
    "    #print('CV accuracy scores: %s' % scores)\n",
    "    print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "_\"As concluding remarks about ensemble techniques, it is worth noting that ensemble learning increases the computational complexity compared to individual classifiers. In practice, we need to think carefully about whether we want to pay the price of increased computational costs for an often relatively modest improvement in predictive performance._\n",
    "\n",
    "_An often-cited example of this tradeoff is the famous \\$1 million Netflix Prize, which was won using ensemble techniques. The details about the algorithm were published in The BigChaos Solution to the Netflix Grand Prize by A. Toescher, M. Jahrer, and R. M. Bell, Netflix Prize documentation, 2009, which is available at http://www.stat.osu.edu/~dmsl/GrandPrize2009_BPC_BigChaos.pdf. The winning team received the $1 million grand prize money; however, Netflix never implemented their model due to its complexity, which made it infeasible for a real-world application:_\n",
    "\n",
    "_\"We evaluated some of the new methods offline but the additional accuracy gains that we measured did not seem to justify the engineering effort needed to bring them into a production environment.\" http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html\"_ Python Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Example Project\n",
    "\n",
    "__TODO__\n",
    "- add some pruning to the mix\n",
    "- Dont record this bit, just leave it in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "__[TEXT]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.872570</td>\n",
       "      <td>0.684466</td>\n",
       "      <td>0.814649</td>\n",
       "      <td>0.778518</td>\n",
       "      <td>0.816336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.861407</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.814649</td>\n",
       "      <td>0.783204</td>\n",
       "      <td>0.814649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.694581</td>\n",
       "      <td>0.814649</td>\n",
       "      <td>0.780767</td>\n",
       "      <td>0.815422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>469.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.814649</td>\n",
       "      <td>669.000000</td>\n",
       "      <td>669.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.872570    0.684466  0.814649    0.778518      0.816336\n",
       "recall       0.861407    0.705000  0.814649    0.783204      0.814649\n",
       "f1-score     0.866953    0.694581  0.814649    0.780767      0.815422\n",
       "support    469.000000  200.000000  0.814649  669.000000    669.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT = DecisionTreeClassifier(criterion='gini',\n",
    "                            max_depth = 6,\n",
    "                            random_state=42)\n",
    "\n",
    "DT.fit(X_train, y_train)\n",
    "display(pd.DataFrame(classification_report(y_val, DT.predict(X_val), output_dict=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "__[TEXT]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "__[TEXT]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=274 does not match number of samples=4177",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-162ad5730a3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                          max_depth = None)\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Teaching\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    896\u001b[0m         \"\"\"\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Teaching\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m             raise ValueError(\"Number of labels=%d does not match \"\n\u001b[0m\u001b[0;32m    282\u001b[0m                              \"number of samples=%d\" % (len(y), n_samples))\n\u001b[0;32m    283\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of labels=274 does not match number of samples=4177"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "ET = ExtraTreeClassifier(criterion='gini',\n",
    "                         random_state=42,\n",
    "                         max_depth = None)\n",
    "\n",
    "ET.fit(X, y)\n",
    "\n",
    "display(pd.DataFrame(classification_report(y_val, DT.predict(X_val), output_dict=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Random Forest/Extra Trees\n",
    "\n",
    "Advantage:\n",
    "- _\"Random forests are an effective tool in prediction. Because of the Law of Large Numbers they do not overfit. Injecting the right kind of randomness makes them accurate classifiers and regressors\"_ Breiman L: Random forests. Machine Learning 2001, 45: 5–32.\n",
    "    - although note the above statement has been questioned in Segal MR: Machine Learning Benchmarks and Random Forest Regression. Technical Report, Center for Bioinformatics & Molecular Biostatistics, University of California, San Francisco 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0     1  accuracy  macro avg  weighted avg\n",
       "precision   1.0   1.0       1.0        1.0           1.0\n",
       "recall      1.0   1.0       1.0        1.0           1.0\n",
       "f1-score    1.0   1.0       1.0        1.0           1.0\n",
       "support    33.0  20.0       1.0       53.0          53.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier(criterion='gini',\n",
    "                                n_estimators=100,\n",
    "                                max_features = 'sqrt',\n",
    "                                class_weight = 'balanced',\n",
    "                                random_state=42,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "ET = ExtraTreesClassifier(criterion='gini',\n",
    "                     n_estimators=100,\n",
    "                     max_features = 'sqrt',\n",
    "                     class_weight = 'balanced',\n",
    "                     random_state=42,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "clf_dict = {\"Random Forest\": RF, \"Extra Trees\": ET}\n",
    "\n",
    "for clf in clf_dict:\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    display(pd.DataFrame(classification_report(y_val, clf.predict(X_val) , output_dict = True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "1. James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. An introduction to statistical learning. Vol. 112. New York: springer, 2013.\n",
    "2. Gorman KB, Williams TD, Fraser WR (2014). Ecological sexual dimorphism and environmental variability within a community of Antarctic penguins (genus Pygoscelis). PLoS ONE 9(3):e90081. https://doi.org/10.1371/journal.pone.0090081\n",
    "3. Géron, A. (2017). Hands-on machine learning with Scikit-Learn and TensorFlow: concepts, tools, and techniques to build intelligent systems. \" O'Reilly Media, Inc.\".\n",
    "4. Raschka, Sebastian, and Vahid Mirjalili. Python Machine Learning, 2nd Ed. Packt Publishing, 2017."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "authorship_tag": "ABX9TyMNuZgSJ2BiDt5YMpOB66EK",
   "collapsed_sections": [],
   "name": "Clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
