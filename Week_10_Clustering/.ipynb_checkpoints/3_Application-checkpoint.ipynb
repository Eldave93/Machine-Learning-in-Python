{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "proper-deposit",
   "metadata": {},
   "source": [
    "## Applications\n",
    "\n",
    "__TODO__\n",
    "- maybe come back to these in the applications section.\n",
    "\n",
    "- _\"A cancer researcher might assay gene expression levels in 100 patients with breast cancer. He or she might then look for subgroups among the breast cancer samples, or among the genes, in order to obtain a better understanding of the disease._ \n",
    "- _An online shopping site might try to identify groups of shoppers with similar browsing and purchase histories, as well as items that are of particular interest to the shoppers within each group. Then an individual shopper can be preferentially shown the items in which he or she is particularly likely to be interested, based on the purchase histories of similar shoppers._\n",
    "- _A search engine might choose what search results to display to a particular individual based on the click histories of other individuals with similar search patterns.\"_<sup>1</sup>\n",
    "---\n",
    "1. An Introduction to Statistical Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-singles",
   "metadata": {},
   "source": [
    "__Applications__\n",
    "- _\"For instance, suppose that we have a set of n observations, each with p features. The n observations could correspond to tissue samples for patients with breast cancer, and the p features could correspond to measurements collected for each tissue sample; these could be clinical measurements, such as tumor stage or grade, or they could be gene expression measurements. We may have a reason to believe that there is some heterogeneity among the n tissue samples; for instance, perhaps there are a few different unknown subtypes of breast cancer. Clustering could be used to find these subgroups. This is an unsupervised problem because we are trying to discover structure—in this case, distinct clusters—on the basis of a data set.\"_\n",
    "\n",
    "- _\"Another application of clustering arises in marketing. We may have access to a large number of measurements (e.g. median household income, occupation, distance from nearest urban area, and so forth) for a large number of people. Our goal is to perform market segmentation by identifying subgroups of people who might be more receptive to a particular form of advertising, or more likely to purchase a particular product. The task of performing market segmentation amounts to clustering the people in the data set.\"_<sup>1</sup>\n",
    "\n",
    "__NOTE__\n",
    "1. think I'll pick the marketing one as the main example for the project\n",
    "\n",
    "---\n",
    "1. An Introduction to Statistical Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-notebook",
   "metadata": {},
   "source": [
    "_\"In order to perform clustering, some decisions must be made._\n",
    " - _Should the observations or features first be standardized in some way? For instance, maybe the variables should be centered to have mean zero and scaled to have standard deviation one.\"_ Intro to Data Sciecnce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-creativity",
   "metadata": {},
   "source": [
    "## Feature Selection and Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-palmer",
   "metadata": {},
   "source": [
    "## Imballanced Data and Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-nomination",
   "metadata": {},
   "source": [
    "## Limits of K-Means\n",
    "- section currently from https://github.com/ageron/handson-ml2/blob/master/09_unsupervised_learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1 = make_blobs(n_samples=1000, centers=((4, -4), (0, 0)), random_state=42)\n",
    "X1 = X1.dot(np.array([[0.374, 0.95], [0.732, 0.598]]))\n",
    "X2, y2 = make_blobs(n_samples=250, centers=1, random_state=42)\n",
    "X2 = X2 + [6, -8]\n",
    "X = np.r_[X1, X2]\n",
    "y = np.r_[y1, y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(X, y=None):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=1)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "\n",
    "plot_clusters(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_good = KMeans(n_clusters=3, init=np.array([[-1.5, 2.5], [0.5, 0], [4, 0]]), n_init=1, random_state=42)\n",
    "kmeans_bad = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans_good.fit(X)\n",
    "kmeans_bad.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3.2))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_decision_boundaries(kmeans_good, X)\n",
    "plt.title(\"Inertia = {:.1f}\".format(kmeans_good.inertia_), fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_decision_boundaries(kmeans_bad, X, show_ylabels=False)\n",
    "plt.title(\"Inertia = {:.1f}\".format(kmeans_bad.inertia_), fontsize=14)\n",
    "\n",
    "#save_fig(\"bad_kmeans_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-academy",
   "metadata": {},
   "source": [
    "Limit\n",
    "\n",
    "_\"clustering methods generally are not very robust to perturbations to the data. For instance, suppose that we cluster n observations, and then cluster the observations again after removing a subset of the n observations at random. One would hope that the two sets of clusters obtained would be quite similar, but often this is not the case!\"_ James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An introduction to statistical learning (Vol. 112, p. 18). New York: springer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-reasoning",
   "metadata": {},
   "source": [
    "# Validating the Clusters <a id='val'></a>\n",
    "\n",
    "_\"We really want to know whether the clusters that have been found represent true subgroups in the data, or whether they are simply a result of clustering the noise. For instance, if we were to obtain an independent set of observations, then would those observations also display the same set of clusters? This is a hard question to answer. There exist a number of techniques for assigning a p-value to a cluster in order to assess whether there is more evidence for the cluster than one would expect due to chance. However, there has been no consensus on a single best approach.\"_<sup>1</sup>\n",
    "\n",
    "---\n",
    "1. Introduction to stats learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-representation",
   "metadata": {},
   "source": [
    "__Notes__\n",
    "- [This](https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation) page on the Scikit-Learn documentation goes over a number of cluster validation approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-cherry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
