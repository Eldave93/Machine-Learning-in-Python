{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "superior-roads",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Big Data, Black Boxes, and Bullsh*t\n",
    "### Dr. David Elliott\n",
    "\n",
    "1.1. [Introduction](#intro)\n",
    "\n",
    "1.2. [Big Data and Bias](#bdb)\n",
    "\n",
    "1.3. [Algorithmic Ethics](#ethics)\n",
    "\n",
    "1.4. [Black Boxes](#blackbox)\n",
    "\n",
    "1.5. [Fixing Bias](#solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-security",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- Essentially a guide to approaching the results from blackbox models\n",
    "\n",
    "__TODO__\n",
    "- Have a look through what to use from ethics week in intro to data science\n",
    "- Continue to read \"Weapons of Math Destruction\" from chapter 8 adding in notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-growth",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction <a id='intro'></a>\n",
    "\n",
    "> The Navy revealed the embryo of an electronic computer today that it expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.\n",
    "\n",
    "July 8, 1958, The New York Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-veteran",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The embryo in question is a perceptron, a simple logical circuit designed to mimic a biological neuron.\n",
    "\n",
    "It takes a set of numerical values as inputs, and then spits out either a 0 or a 1.\n",
    "\n",
    "![Image from Python Machine Learning](./Images/perceptron.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-miracle",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Connect enough of these perceptrons together in the right ways, and you can build:\n",
    "\n",
    "- a chess-playing computer, \n",
    "- a self-driving car, \n",
    "- an algorithm that translates speech. \n",
    "\n",
    "Though the computer hardware is vastly more powerful, the basic approach remains similar to how it was a half century ago."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-turkish",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- See the notebook on Deep Learning for more of an introduction\n",
    "> - The inventor of the perceptron, Frank Rosenblatt, was a psychologist by training, with broad interests in astronomy and neurobiology. \n",
    ">    - He used a two-million-dollar IBM 704 computer to simulate his first perceptron. \n",
    ">    - He also had a knack for selling big ideas and described his work in grandiose terms. \n",
    ">    - His machine, he told The New York Times, would think the way that humans do and learn from experience. Someday, he predicted, his perceptrons would be able to recognize faces and translate speech in real time. Perceptrons would be able to assemble other perceptrons, and perhaps even attain consciousness. Someday they could become our eyes and ears in the universe, sent out beyond the bounds of Earth to explore the planets and stars on our behalf.<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-hundred",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The hype hasn’t diminished<sup>2<sup>.\n",
    "\n",
    "> ...will make possible a new generation of artificial intelligence [AI] systems that will perform some functions that humans do with ease: see, speak, listen, navigate, manipulate and control.\n",
    "\n",
    "December 28, 2013, The New York Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-stewart",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Advances in AI are great and are spurring a lot of economic activity. However there is currently unreasonable expectations, which drives<sup>2<sup>:\n",
    "- irresponsible research in both industry and academia, \n",
    "- threats to personal privacy,\n",
    "- motivates misdirected policy. \n",
    "    \n",
    "> \"Policy makers [are] earnestly having meetings to discuss the rights of robots when they should be talking about discrimination in algorithmic decision making.\" \n",
    "\n",
    "Zachary Lipton, AI researcher at Carnegie Mellon University"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-passport",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- Hype Machine:\n",
    "    - Newspapers gush about the latest breakthrough. \n",
    "    - AI jobs are paying superstar salaries. \n",
    "    - Tech firms are wooing away from campus professors with AI expertise. \n",
    "    - Venture capital firms are throwing money at anyone who can say \"deep learning\" with a straight face.\n",
    "- _\"Researchers and technologists spend far too much time focusing on the sexy what-might-be, and far too little time on the important what-is.\"_<sup>2<sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-spotlight",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "_\"[AI poses a] fundamental risk to the existence of human civilization.\"_ Elon Musk, 2017\n",
    "\n",
    "_\"AI Is Inventing Languages Humans Can’t Understand. Should We Stop It?\"_ Fast Company article\n",
    "\n",
    "> BOB THE BOT: \"I can can I I everything else.\"\n",
    ">\n",
    "> ALICE THE BOT: \"Balls have zero to me to me to me to me to me to me to me to me to.\"\n",
    ">\n",
    "> BOB: \"You I everything else.\"\n",
    ">\n",
    "> ALICE: \"Balls have a ball to me to me to me to me to me to me to me to me.\"\n",
    "\n",
    "The original Facebook blog post simply described a chatbot evolving the repetition of nonsensical sentences, which was dramatically distorted to a story about saving the human race. \n",
    "\n",
    "_\"There was no panic,\"_ one researcher said, _\"and the project hasn’t been shut down.\"_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-shape",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "\n",
    "- _\"There is a vast gulf between AI alarmism in the popular press, and the reality of where AI research actually stands.\"_<sup>2</sup>\n",
    "- _\"The story described a Facebook research project gone awry. While trying to build a chatbot that could carry on a convincing conversation, researchers tried having computer algorithms train one another to speak. But the speech that the algorithms developed was nothing like human language. Fast Company reported that the researchers quickly shut down the project. Skynet was officially on its way to self-awareness, but disaster had been averted—or so the story, and many others like it, suggested.\"_<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-wagner",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Compared to the human brain, machine learning isn’t especially efficient. \n",
    "\n",
    "A child can learn that stoves are hot by touching it once, connects the hot metal and her throbbing hand, and picks up the word for it: burn. \n",
    "\n",
    "A machine learning program requires millions or billions of data points to create its statistical models. \n",
    "\n",
    "Its only now those petabytes of data are now readily available, along with powerful computers to process them<sup>13</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-leadership",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- _\"[In] machine learning, a fast-growing domain of artificial intelligence, the computer dives into the data, following only basic instructions. The algorithm finds patterns on its own, and then, through time, connects them with outcomes. In a sense, it learns.\"_<sup>13</sup>.\n",
    "- Perceptrons used in todays deep learning models no longer reflect human biology, they are just inspired by it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-owner",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For many jobs, machine learning proves to be more flexible and nuanced than the traditional programs governed by rules<sup>13</sup>.\n",
    "\n",
    "Furthermore, Rosenblatt deserves credit because many of his ambitious predictions have come true:\n",
    "\n",
    "- Facial recognition technology, \n",
    "- virtual assistants, \n",
    "- machine translation systems, \n",
    "- stock-trading bots \n",
    "\n",
    "...are all built using perceptron-like algorithms<sup>2</sup>.\n",
    "\n",
    "Most of the recent breakthroughs in machine learning are due to the masses of data available and the processing power to deal with it, rather than a fundamentally different approach. \n",
    "    \n",
    "However you cannot compensate for bad data, if someone tells you otherwise, they are talking bullshit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-joining",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Bullshit? <a id='what'></a>\n",
    "Jevin West and Carl Bergstrom define bullshit as<sup>2</sup>:\n",
    "\n",
    "> Bullshit involves language, statistical figures, data graphics, and other forms of presentation intended to persuade or impress an audience by distracting, overwhelming, or intimidating them with a blatant disregard for truth, logical coherence, or what information is actually being conveyed.\n",
    "\n",
    "__TODO__\n",
    "- bit more on this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-amsterdam",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "\n",
    "- _\"G. A. Cohen, notes that a lot of bullshit—particularly of the academic variety—is meaningless and so cloaked in rhetoric and convoluted language that no one can even critique it. Thus for Cohen, bullshit is “unclarifiable unclarity.”\"_<sup>2</sup>\n",
    "- _\"Neil Postman’s dictum, “At any given time, the chief source of bullshit with which you have to contend is yourself.”_<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-skiing",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Big Data and Bias <a id='bdb'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-atmosphere",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We live in an ever increasing quantified world, where everything is counted, measured, and analyzed<sup>2</sup>:\n",
    "\n",
    "- Smartphones count our steps, measure our calls, and trace our movements. \n",
    "- \"Smart appliances\" monitor use and learn about daily routines. \n",
    "- Implanted medical devices continuously collect data and predict emergencies. \n",
    "- Sensors and cameras are across our cities monitoring traffic, air quality, and pedestrian identities.\n",
    "\n",
    "We've also moved from companies paying customers to complete surveys to them recording what we do<sup>2</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-transportation",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "\n",
    "- What do they know<sup>2</sup>?\n",
    "> - Facebook knows whom we know; Google knows what we want to know. \n",
    "> - Uber knows where we want to go; Amazon knows what we want to buy. \n",
    "> - Match knows whom we want to marry; Tinder knows whom we want to be swiped by."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-animation",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Mathematicians and statisticians use this data to study our desires, movements, and spending power. \n",
    "\n",
    "They predict our trustworthiness and calculating our potential as students, workers, lovers, and criminals. \n",
    "\n",
    "This is the _\"Big Data economy\"_, and it promises spectacular gains. These algorithms not only save time and money but are \"fair\" and \"objective\". After all, they don't involve prejudiced humans, just machines processing cold numbers<sup>13</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-perspective",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Numbers feel objective, but are easily manipulated. \n",
    "\n",
    "Numbers suggest precision and imply a scientific approach, appearing to have an existence separate from the humans reporting them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-uncle",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![image info](./Images/Calvin_Hobbes_Data_Quality.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-mineral",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "\n",
    "- _\"It’s like the old joke:<sup>2</sup>_\n",
    "    > A mathematician, an engineer, and an accountant are applying for a job. They are led to the interview room and given a math quiz. The first problem is a warm-up: What is 2 + 2? The mathematician rolls her eyes, writes the numeral 4, and moves on. The engineer pauses for a moment, then writes “Approximately 4.” The accountant looks around nervously, then gets out of his chair and walks over to the fellow administering the test. “Before I put anything in writing,” he says in a low whisper, “what do you want it to be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-exhibition",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "More sinisterly, many models encode human prejudice, misunderstanding, and bias into the software systems. \n",
    "\n",
    "These mathematical models are opaque, their workings invisible to all but mathematicians and computer scientists*. \n",
    "\n",
    "Their verdicts, even when wrong or harmful, beyond dispute or appeal. \n",
    "\n",
    "They tend to punish the poor and the oppressed in our society, while making the rich richer<sup>13</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-criminal",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "\n",
    "*even then they are often deliberately made to be hard/impossible to understand!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-kitchen",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "_\"No algorithm, no matter how logically sound, can overcome flawed training data.\"_<sup>2</sup>\n",
    "\n",
    "Good training data is difficult and expensive to obtain. \n",
    "\n",
    "Training data often comes from the real world, but the real world is full of human biases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-cowboy",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- _\"For various reasons, the glamorous side of machine learning research involves developing new algorithms or tweaking old ones. But what is more sorely needed is research on how to select appropriate, representative data. Advances in that domain would pay rich dividends.\"_<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-shanghai",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sampling Error\n",
    "\n",
    "As exact counts and exhaustive measurements are nearly always impossible, we take small samples of a larger group and using that information to make broader inferences.\n",
    "\n",
    "__Example__<sup>2</sup>\n",
    "\n",
    "_\"If one measured only a half dozen men and took their average height, it would be easy to get a misleading estimate simply by chance. Perhaps you sampled a few unusually tall guys. Fortunately, with large samples things tend to average out, and sampling error will have a minimal effect on the outcome.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-hungary",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Measurement Error\n",
    "\n",
    "This is more of a systematic error caused by or measurement method.\n",
    "\n",
    "__Example__<sup>2</sup>\n",
    "\n",
    "_\"Researchers might ask subjects to report their own heights, but men commonly exaggerate their heights—and shorter men exaggerate more than taller men.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-extent",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "_\"algorithms are a powerful tool for behavioral modification.\"_<sup>13</sup>\n",
    "\n",
    "When a measure becomes a target, it ceases to be a good measure.\n",
    "\n",
    "> The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it is intended to monitor. \n",
    "\n",
    "Donald Campbell\n",
    "\n",
    "__Example__\n",
    "\n",
    "Standardized testing can be valuable indicators of general school achievement under normal teaching conditions. But when test scores become the _goal_ of teaching, they both lose their value as indicators and distort the educational process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-jimmy",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- We'll come back to the standardized testing in education example later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-trout",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Selection Bias\n",
    "\n",
    "Selection bias arises when sampled individuals differ systematically from the population eligible for your study.\n",
    "\n",
    "__Example__<sup>2</sup>\n",
    "\n",
    "_\"Suppose you decide to estimate people’s heights by going to the local basketball court and measuring the players. Basketball players are probably taller than average, so your sample will not be representative of the population as a whole, and as a result your estimate of average height will be too high.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-martin",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What you see depends on where you look\n",
    "\n",
    "__Example__<sup>2</sup>\n",
    "\n",
    "_\"People turn to Google when looking for help, and turn to Facebook to boast.\"_\n",
    "\n",
    "![image info](./Images/husband_fb.png)\n",
    "\n",
    "![image info](./Images/husband_gl.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-motivation",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Outliers\n",
    "\n",
    "Outliers can significantly skew data. In some data they are naturally part of what you are measuring, but need to be intepreted appropriately and accounted for.\n",
    "\n",
    "__Example__<sup>3</sup>\n",
    "\n",
    "When analyzing income in the United States, there are a few extremely wealthy individuals whose income can influence the average income. For this reason, a median value is often a more accurate representation of the larger population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "environmental-finder",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# TODO some code showing this (look at IDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-iceland",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cognitive bias\n",
    "    \n",
    "There are tonnes of human biases that have been defined and classified by psychologists; each affecting individual decision making.\n",
    "\n",
    "These include feelings towards a person based on their perceived group membership. \n",
    "\n",
    "These biases could seep into machine learning algorithms via either<sup>4</sup>:\n",
    "- designers unknowingly introducing them to the model\n",
    "- a training data set which includes those biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-lesson",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Algorithmic Ethics <a id='ethics'></a>\n",
    "\n",
    "_\"Machines are not free of human biases; they perpetuate them, depending on the data they’re fed.\"_<sup>2</sup>\n",
    "\n",
    "Despite appearing impartial, models reflect goals and ideology<sup>13</sup>.\n",
    "\n",
    "Our values and desires influence our choices, from the data we choose to collect to the questions we ask<sup>13</sup>.\n",
    "\n",
    "Whether or not a model works is a matter of opinion. A key component of every model, whether formal or informal, is its definition of success<sup>13</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-parts",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- _\"When we train machines to make decisions based on data that arise in a biased society, the machines learn and perpetuate those same biases.\"_<sup>2</sup>\n",
    "\n",
    "__Todo__\n",
    "- Notes from Weapons of math destruction\n",
    "- talk about the work from teh women fired from Google\n",
    "- Oversight of algorithms needed\n",
    "- Alorightm ethics textbook notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-relationship",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As good training data is hard to come by, it is often the case we lack the data for the behaviors they’re most interested in classifying/predicting. Therefore proxies are used instead. \n",
    "\n",
    "However, proxies are easier to manipulate than the complicated reality they represent<sup>13</sup>.\n",
    "\n",
    "__Example__\n",
    "\n",
    "TEACHING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-shuttle",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Machine injustice\n",
    "\n",
    "We may want to develop a model that can predict whether someone will pay back a loan or handle a job. \n",
    "\n",
    "As this is a prediction about something that may happen in the future we don't know the outcome yet, so we may be tempted to  include factors such as a person’s _postcode_ or _language patterns_. \n",
    "\n",
    "These features can be discriminatory, and some of them are illegal<sup>13</sup>.\n",
    "\n",
    "Even if we do not use \"race\" as a varible in our models, as our society is largely segregated by geography, this is a highly effective proxy for race<sup>13</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-finance",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Examples\n",
    "\n",
    "__Criminal Sentencing:__ Algorithms identify black defendants as \"future\" criminals at nearly twice the rate as white defendants, which leads to differences in pretrial release, sentencing, and parole deals<sup>2, ProPublica</sup>.\n",
    "\n",
    "__Interest Rates:__ Algorithmic lenders charge higher interest rates to both black and Latino applicants<sup>2, REF</sup>\n",
    "\n",
    "__Hiring Software__: Automated hiring software have preferentially selected men over women<sup>2,AMAZON</sup>\n",
    "\n",
    "__College (University) Admissions:__<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-brother",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Criminal Sentencing\n",
    "\n",
    "_\"racism is the most slovenly of predictive models. It is powered by haphazard data gathering and spurious correlations, reinforced by institutional inequities, and polluted by confirmation bias.\"_<sup>13</sup>\n",
    "\n",
    "_\"The question, however, is whether we’ve eliminated human bias or simply camouflaged it with technology. The new recidivism models are complicated and mathematical. But embedded within these models are a host of assumptions, some of them prejudicial.\"_<sup>13</sup>\n",
    "\n",
    "_\"This is the basis of our legal system. We are judged by what we do, not by who we are. And although we don’t know the exact weights that are attached to these parts of the test, any weight above zero is unreasonable.\"_<sup>13</sup>\n",
    "\n",
    "_\"sentencing models that profile a person by his or her circumstances help to create the environment that justifies their assumptions.\"_<sup>13</sup>\n",
    "\n",
    "_\"The penal system is teeming with data, especially since convicts enjoy even fewer privacy rights than the rest of us. What’s more, the system is so miserable, overcrowded, inefficient, expensive, and inhumane that it’s crying out for improvements. Who wouldn’t want a cheap solution like this?\"_<sup>13</sup>\n",
    "\n",
    "_\"police make choices about where they direct their attention. Today they focus almost exclusively on the poor... And now data scientists are stitching this status quo of the social order into models...we criminalize poverty, believing all the while that our tools are not only scientific but fair.\"_<sup>13</sup>\n",
    "\n",
    "#### Interest Rates\n",
    "\n",
    "_\"attempting to reduce human behavior, performance, and potential to algorithms is no easy job.\"_<sup>13</sup>\n",
    "\n",
    "#### Hiring Software\n",
    "_\"If you remove names from résumés as a way of eliminating gender discrimination, you may be disappointed, as Amazon was, when the machine continues to preferentially choose men over women. Why? Amazon trained the algorithm on its existing résumés, and there are features on a résumé besides a name that can reveal one’s gender—such as a degree from a women’s college, membership in a women’s professional organization, or a hobby with skewed gender representation.\"_<sup>2</sup>\n",
    "\n",
    "#### College (University) Admissions\n",
    "\n",
    "So they do still affect the _\"rich and middle class\"_, although this is generally less common. More often the privileged, are processed more by people, and the rest by machines<sup>13</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-relative",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "_\"Programmers don’t know how to code for [fairness], and few of their bosses ask them to.\"_<sup>13</sup>\n",
    "\n",
    "Statisticians count on large numbers to balance out exceptions and anomalies in data, but that means they punish individuals who happen to be the exception<sup>13</sup>.\n",
    "\n",
    "Its easy to loose sight of the impact on people who become the errors, they are _\"collateral damage\"_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-possible",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- Algorithms are made to favor efficiency not fairness - thats hard to quantify.\n",
    "- _\"the real world, with all of its messiness, sits apart. The inclination is to replace people with data trails, turning them into more effective shoppers, voters, or workers to optimize some objective. This is easy to do, and to justify, when success comes back as an anonymous score and when the people affected remain every bit as abstract as the numbers dancing across the screen.\"_<sup>13</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-postage",
   "metadata": {},
   "source": [
    "### Weapons of Math Destruction (WMD's)<sup>13</sup>\n",
    "\n",
    "WMD's, as defined by Cathy O'Neil, have three elements: Opacity, Scale, and Damage.\n",
    "\n",
    "__Opacity__\n",
    "\n",
    "_\"WMDs are, by design, inscrutable black boxes. That makes it extra hard to definitively answer the second question: Does the model work against the subject’s interest? In short, is it unfair? Does it damage or destroy lives?\"_<sup>13</sup>\n",
    "\n",
    "Assumptions of these models are hidden by math, complicated code, or _\"proprietary\"_ licences, so go untested and unquestioned.\n",
    "\n",
    "Its hard to question the output, and as it uses math, human victims are held to a high standard of evidence.\n",
    "\n",
    "__Scale__\n",
    "\n",
    "_\"A formula...might be perfectly innocuous in theory. But if it grows to become a national or global standard, it creates its own distorted and dystopian economy.\"_<sup>13</sup>\n",
    "\n",
    "__Damage__\n",
    "\n",
    "_\"They define their own reality and use it to justify their results. This type of model is self-perpetuating, highly destructive—and very common.\"_<sup>13</sup>\n",
    "\n",
    "Results from these models are often taken as fact.\n",
    "\n",
    "They often feed into a viscious cycle creating a feedback loop that makes the model appear reliable and sustain its use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-craps",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Black Boxes <a id='blackbox'></a>\n",
    "\n",
    "Any black box has to take in data and spit results out.\n",
    "\n",
    "Most often, bullshit arises either because there are biases in the data, or because there are obvious problems with the output, or in its interpretation. \n",
    "\n",
    "Only ocasionally the technical details of the black box matter to spot issues.\n",
    "\n",
    "![image info](./Images/black_box.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-joshua",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "\n",
    "- Of course the technical details of the black box matter if you want to develop models, here we are talking about spotting issues!\n",
    "- Here was are focusing on the black box being an ML model but they can take a variety of forms<sup>2</sup>:\n",
    "    - _\"According to Latour, scientific claims are typically built upon the output of metaphorical “black boxes,” which are difficult if not impossible for the reader to penetrate. These black boxes often involve the use of specialized and often expensive equipment and techniques that are time-consuming and unavailable, or are so broadly accepted that to question them represents a sort of scientific heresy.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-apache",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Question__\n",
    "\n",
    "But I've been learning ML, I should be able to understand the model, so why does this apply to me?\n",
    "\n",
    "__Answer__ \n",
    "\n",
    "- A lot of applied ML research papers do not describe their algorithms in sufficient detail, or are _\"proprietary\"_. \n",
    "\n",
    "- In \"Deep learning\" models, no one—including the creators of the algorithm—fully understands the workings of the program that algorithm generates.\n",
    "\n",
    "- There are hundreds of tweaks to the basic architectures of ML methods so its impossible to know them all! Before investing your time learning a new approach its good to check if the authors claims are justified.\n",
    "\n",
    "![image info](./Images/ml_black_box.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-asbestos",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- [INSERT]\n",
    "\n",
    "__TODO__\n",
    "- Explain paper used in thesis showing how many models are not reproducible or replicable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-campbell",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training Data\n",
    "\n",
    "> \"On two occasions I have been asked, 'Pray, Mr. Babbage, if you put into the machine wrong figures, will the right answers come out?' … I am not able rightly to apprehend the kind of confusion of ideas that could provoke such a question.\"\n",
    "Charles Babbage\n",
    "\n",
    "As data is so central to these systems, to spot problems we can start by looking at the training data and the labels. \n",
    "\n",
    "Begin with bad data and labels, and you’ll get a bad program that makes bad predictions in return. \n",
    "\n",
    "GIGO: garbage in, garbage out.\n",
    "\n",
    "__Some checks__<sup>2</sup>\n",
    "- Are the data unbiased, reasonable, and relevant to the problem at hand? \n",
    "- Do the results pass basic plausibility checks? \n",
    "- Do they support whatever conclusions are drawn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-thompson",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- _\"If the data that go into the analysis are flawed, the specific technical details of the analysis don’t matter.One can obtain stupid results from bad data without any statistical trickery. And this is often how bullshit arguments are created, deliberately or otherwise. To catch this sort of bullshit, you don’t have to unpack the black box. All you have to do is think carefully about the data that went into the black box and the results that came out.\"_<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-mambo",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Outputs/Interpretation\n",
    "\n",
    "_\"extraordinary claims require extraordinary evidence.\"_<sup>2</sup>\n",
    "\n",
    "__Logical Checks__<sup>2</sup>\n",
    "- Reductio Ad Absurdum\n",
    "- Find Counter Examples\n",
    "- Deploy a Null Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-connecticut",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reductio Ad Absurdum\n",
    "\n",
    "[EXAMPLATION]\n",
    "\n",
    "__Example__\n",
    "\n",
    "Momentous sprint at the 2156 Olympics?<sup>5</sup>\n",
    "\n",
    "![image info](./Images/sprint.png)\n",
    "\n",
    "The regression lines are extrapolated (broken blue and red lines for men and women, respectively) and 95% confidence intervals (dotted black lines) based on the available points are superimposed. The projections intersect just before the 2156 Olympics, when the winning women's 100-metre sprint time of 8.079 s will be faster than the men's at 8.098 s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-adams",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> Sir—A. J. Tatem and colleagues calculate that women may outsprint men by the middle of the twenty-second century (Nature 431, 525; 200410.1038/431525a). They omit to mention, however, that (according to their analysis) a far more interesting race should occur in about 2636, when times of _less than zero seconds_ will be recorded. In the intervening 600 years, the authors may wish to address the obvious challenges raised for both time-keeping and the teaching of basic statistics.\n",
    "\n",
    "Ken Rice, Biostatistics Professor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-uganda",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- _\"It may be true that women will someday outsprint men, but this analysis does not provide a compelling argument. The authors’ conclusions were based on an overly simplistic statistical model. As shown above, the researchers fit a straight line through the times for women, and a separate straight line through the times for men. If you use this model to estimate future times, it predicts that women will outsprint men in the year 2156. In that year, the model predicts that women will finish the hundred-meter race in about 8.08 seconds and men will be shortly behind with times of about 8.10 seconds. Of course, both women and men will continue to break records. However, there is something clearly wrong with the model.\"_<sup>2</sup>\n",
    "- _\"A model may pass all the formal statistical model-fitting tests. But if it does not account for real biology—in this case, the physical limits to how fast any organism can run—we should be careful about what we conclude.\"_<sup>2</sup>\n",
    "- A favourite example of mine of \"Reductio Ad Absurdum\" from the neuroscience litriture is the dead salmon study: [Craig Bennett et al. (2009), Neural correlates of interspecies perspective taking in the post-mortem Atlantic Salmon: An argument for multiple comparisons correction](http://prefrontal.org/files/posters/Bennett-Salmon-2009.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-affairs",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Find Counter Examples\n",
    "\n",
    "_\"If someone claims that A implies B, find a case in which A is true but B is not.\"_<sup>2</sup>\n",
    "\n",
    "__Example__\n",
    "- Try find a more ML relevent example than in the book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-bermuda",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "__Extra__<sup>2</sup>\n",
    "\n",
    "Fermat’s last theorem (more of a conjecture due to lack of proof) was that there are no three distinct integers $a$, $b$, and $c$ such that $a^n + b^n = c^n$ for integer values of $n$ greater than 2. This was attempted to be proved for centries (e.g. Andrew Wiles). \n",
    "\n",
    "It was later generalized by eighteenth-century mathematician Leonhard Euler into the sum of powers conjecture: for integers $a, b, c, \\ldots, z$ and any integer $n$, if you want numbers $a^n, b^n, c^n, \\ldots$, to add to some other number $z^n$, you need at least $n$ terms in the sum. Again time passed with no way of proving or disproving this, until 1966 when two mathematicians used an early computer to run through a huge list of possibilities and found  the counterexample below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "consecutive-nashville",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27**5 + 84**5 + 110**5 + 133**5 == 144**5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-think",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Deploy a Null Mode\n",
    "\n",
    "_\"The point of a null model is not to accurately model the world, but rather to show that a pattern X, which has been interpreted as evidence of a process Y, could actually have arisen without Y occurring at all\"._\n",
    "\n",
    "__Example__<sup>6</sup>\n",
    "\n",
    "The following is a plot intended to demonstrate how as we age our pysical and cognative abilities decline. \n",
    "\n",
    "_\"The figure below shows the average speed of world record holders in the men’s 100-meter, 1,500-meter, and 10,000-meter race, with the speeds normalized so that the world record corresponds to a pace of 1.0.\"_<sup>2</sup>\n",
    "\n",
    "![image info](./Images/senescence.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-litigation",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- Remember, we deployed a null model when looking at ML on imballanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-liberty",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "_\"There are many more people running competitively in their twenties and thirties than in their seventies and eighties. The more runners you sample from, the faster you expect the fastest time to be.\"_<sup>2</sup>\n",
    "\n",
    "_\"We might see the same decreasing trend in speed simply as a consequence of sample size, even if runners did not get slower with age.\"_<sup>2</sup>\n",
    "\n",
    "_\"we can create a null model. A null model helps us understand what we would observe in a very simple system where not much is going on. In this case we can use a computer simulation to create a pretend world where age doesn’t affect running speed. Then we see if we still observe the same downward trend in physical performance simply because there are fewer runners of older ages. The graph in the previous page illustrates what we find.\"_<sup>2</sup>\n",
    "\n",
    "![image info](./Images/senescence_null.png)\n",
    "\n",
    "_\"This does not mean that senescence is a myth. What it does mean is that the data Carl plotted do not provide compelling evidence of senescence, because the null model shows the same result without senescence.\"_<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-comparative",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- _\"If we were looking at average speed, the sample size wouldn’t matter much. Whether we sampled a hundred, a thousand, or a million runners of a given age, we would expect the average time to be about the same. But if we are looking at the extreme outliers, the sample size matters.\"_<sup>2</sup>\n",
    "\n",
    "- Other valid objections include<sup>2</sup>:\n",
    "    - _\"These are world record times set by the world’s best athletes. The performance curve above may not be representative of what happens to the rest of us.\"_\n",
    "    - _\"...the curve shown does not represent the performance trajectory of any single individual.\"_\n",
    "    - _\"there may be \"cohort effects\" operating. Runners who set records in the sixty-five-and-over group trained using different techniques, diets, etc., than runners currently in their twenties. Improved training technology could have an effect on record times as well.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-european",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Case Study<sup>2,7</sup>\n",
    "\n",
    "__Automated Inference on Criminality Using Face Images__<sup>8</sup>\n",
    "\n",
    "> _Unlike a human examiner/judge, a computer vision algorithm or classifier has absolutely no subjective baggages [sic], having no emotions, no biases whatsoever due to past experience, race, religion, political doctrine, gender, age, etc., no mental fatigue, no preconditioning of a bad sleep or meal. The automated inference on criminality eliminates the variable of meta-accuracy (the competence of the human judge/examiner) all together._<sup>8</sup>\n",
    "\n",
    "The idea criminals are betrayed by their physiognomy is not new (e.g. Cesare Lombroso<sup>9</sup>), and its been debunked for the racist and unscientific bullshit it was before.\n",
    "\n",
    "The problem with this new study can be identified in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-average",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![image info](./Images/criminals.jpg)\n",
    "![image info](./Images/non-criminals.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-minimum",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The criminal faces used to train the algorithm were seldom smiling, whereas the noncriminal faces were usually smiling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-sunrise",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- I like this example due to it highlighting the same BS psychology studies that were debunked years ago are coming back in parts of the ML litriture. Back then they used \"Science\" to justify their claims, now these modern researchers use terms such as \"Artificial Intelligence\", \"Big Data\", or \"Machine Learning\", to justify the same garbage in a new package.\n",
    "- I suggest you watch the section of the lecture where this example is more throughly explored and entertainingly elaberated on: [Calling Bullshit 5.5: Criminal Machine Learning](https://www.youtube.com/watch?v=rga2-d1oi30&list=PLPnZfvKID1Sje5jWxt-4CSZD7bUI4gSPS&index=27)\n",
    "- Note this study falls under the issue I highlighted earlier in that there is limited access to the models and training data so we kind of have to focus on the inputs and outputs.\n",
    "- _\"Smiling is not a good indicator of whether someone is a criminal or not, but the machine didn’t know it was supposed to be finding signs of criminality. It was just trying to discriminate between two different sets of faces in the training set. The presence or absence of a smile turned out to be a useful signal, because of the way the training images were chosen.\"_<sup>2</sup>\n",
    "- _\"Phrenology was a model that relied on pseudoscientific nonsense to make authoritative pronouncements, and for decades it went untested. Big Data can fall into the same trap. Models...can lock people out, even when the “science” inside them is little more than a bundle of untested assumptions.\"_<sup>13</sup>\n",
    "- An additional example is [ml_sexual_orientation](https://www.callingbullshit.org/case_studies/case_study_ml_sexual_orientation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-connecticut",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## When Models Fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-bidder",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A number of ML algorithms create their own rules to make decisions—and these rules often make little sense to humans<sup>2</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-invalid",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sometimes these rules can be fooled surprisingly easily:\n",
    "\n",
    "__Fooling Deep Nets__\n",
    "\n",
    "https://arxiv.org/pdf/1412.1897.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-timber",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sometimes these rules focus on unintended aspects of the training data.\n",
    "\n",
    "__Example__<sup>10</sup>\n",
    "\n",
    "Ribeiro et al. (2016) developed an automated method for distinguishing photographs of huskies from wolves. \n",
    "\n",
    "By looking at the errors (e.g. where a husky is classified as a wolf), they demonstrated the importance of looking at what information the algorithm was using.\n",
    "\n",
    "![image info](./Images/husky_wolf.jpg)\n",
    "![image info](./Images/explain.jpg)\n",
    "\n",
    "Wolf images tended to be shot in the snow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-webster",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- This model would not generalise very well!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-canyon",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "__Extra Example__\n",
    "\n",
    "_\"John Zech and colleagues at California Pacific Medical Center wanted to investigate how well neural networks could detect pathologies such as pneumonia and cardiomegaly—enlarged heart—using X-ray images. The team found that their algorithms performed relatively well in hospitals where they were trained, but poorly elsewhere....It turned out that the machine was cueing on parts of the images that had nothing to do with the heart or lungs. For example, X-ray images produced by a portable imaging device had the word PORTABLE printed in the upper right corner—and the algorithm learned that this is a good indicator that a patient has pneumonia. Why? Because portable X-ray machines are used for the most severely ill patients, who cannot easily go to the radiology department of the hospital. Using this cue improved prediction in the original hospital. But it was of little practical value. It had little to do with identifying pneumonia, didn’t cue in on anything doctors didn’t already know, and wouldn’t work in a different hospital that used a different type of portable X-ray machine.\"_<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-situation",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Overfitting\n",
    "\n",
    "Complicated models do a great job of fitting the training data, but simpler models often perform better on the test data. The hard part is figuring out just how simple of a model to use.<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-freeware",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Case Study<sup>11</sup>\n",
    "\n",
    "__Detecting Influenza Epidemics Using Search Engine Query Data__\n",
    "\n",
    "A method for predicting flu outbreaks based on Google search queries.\n",
    "\n",
    "It worked well for a few years but the results started to miss the mark by a factor of two and it was eventually axed.\n",
    "\n",
    "_\"There was no theory about what search terms constituted relevant predictors of flu, and that left the algorithm highly susceptible to chance correlations in timing.\"_<sup>2</sup>\n",
    "\n",
    "_\"When the frequency of search queries changes, the rules that the algorithm learned previously may no longer be effective.\"_<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-fifth",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Curse of Dimensionality.\n",
    "\n",
    "_\"Many modern complicated algorithms use dozens, hundreds, or even thousands of variables when making predictions.\"_<sup>2</sup>\n",
    "\n",
    "_\"Google Flu Trends relied on forty-five key search queries that best predicted flu outbreaks. A machine learning system designed to detect cancer might look at a thousand different genes.\"_<sup>2</sup>\n",
    "\n",
    "The more variables you add, the more training data you need, and this can be costly. _\"If you have ten thousand genes you want to incorporate into your model, good luck in finding the millions of example patients that you will need to have any chance of making reliable predictions.\"_<sup>2</sup>\n",
    "\n",
    "_\"If you add enough variables into your black box, you will eventually find a combination of variables that performs well—but it may do so by chance. As you increase the number of variables you use to make your predictions, you need exponentially more data to distinguish true predictive capacity from luck.\"_<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-laundry",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "__Notes__\n",
    "- For an expanded discussion of this, watch [Calling Bullshit 5.3: Big Data Hubris](https://www.youtube.com/watch?v=X0XqnAqvyIk&list=PLPnZfvKID1Sje5jWxt-4CSZD7bUI4gSPS&index=25)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-raise",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fixing bias <a id='solutions'></a>\n",
    "\n",
    "https://research.aimultiple.com/ai-bias/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-advertising",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Compliment rather than supplement humans\n",
    "\n",
    "Big data, machine learning are not meant to replace humans, just supplement.\n",
    "\n",
    "Use the flu trends lessone from this lecture: https://www.youtube.com/watch?v=X0XqnAqvyIk&list=PLPnZfvKID1Sje5jWxt-4CSZD7bUI4gSPS&index=25\n",
    "        \n",
    "Also put in a bit from \"Deep Medicine\" :D\n",
    "\n",
    "_\"When you have Google-scale data, argued Wired editor Chris Anderson, “the numbers speak for themselves.” The scientific method was no longer necessary, he argued; the huge volumes of data would tell us everything we need to know. Data scientists didn’t need years of epidemiological training or clinicians to diagnose flu symptoms. They just need enough data to “nowcast”fn12 the flu and inform the CDC where to deliver Tamiflu. Or so we were told._\"<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-vertical",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "_\"When it comes to open-ended tasks involving judgment and discretion, there is still no substitute for human intervention. Identifying fake news, detecting sarcasm, creating humor—for now, these are areas in which machines fall short of their human creators. However, reading addresses is relatively simple for a computer. The digit classification problem—figuring out whether a printed digit is a one, a two, a three, etc.—is a classic application of machine learning.\"_\n",
    "\n",
    "West, Jevin D.; Bergstrom, Carl T.. Calling Bullshit (p. 186). Penguin Books Ltd. Kindle Edition. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-factory",
   "metadata": {},
   "source": [
    "## Continual Updating\n",
    "\n",
    "_\"But how does it ever learn if it was right? It doesn’t. The system itself has determined that they were failures, and that is how they are viewed.\"_<sup>13</sup>\n",
    "\n",
    "_\"trustworthy models operate. They maintain a constant back-and-forth with whatever in the world they’re trying to understand or predict. Conditions change, and so must the model.\"_<sup>13</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-survivor",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Transparency/Accountability\n",
    "\n",
    "_\"To address the major impact that algorithms have on human lives, researchers and policy makers alike have started to call for algorithmic accountability and algorithmic transparency. Algorithmic accountability is the principle that firms or agencies using algorithms to make decisions are still responsible for those decisions, especially decisions that involve humans. We cannot let people excuse unjust or harmful actions by saying “It wasn’t our decision; it was the algorithm that did that.” Algorithmic transparency is the principle that people affected by decision-making algorithms should have a right to know why the algorithms are making the choices that they do. But many algorithms are considered trade secrets.fn10\"_\n",
    "\n",
    "West, Jevin D.; Bergstrom, Carl T.. Calling Bullshit (p. 201). Penguin Books Ltd. Kindle Edition. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-organic",
   "metadata": {},
   "source": [
    "## Leave Information out\n",
    "\n",
    "_\"[Are] we as a society are willing to sacrifice a bit of efficiency in the interest of fairness. Should we handicap the models, leaving certain data out?\"_<sup>13</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-mistress",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Refuting Bullshit\n",
    "\n",
    "> \"At any given time, the chief source of bullshit with which you have to contend is yourself.\"\n",
    "Neil Postman\n",
    "\n",
    "We are subject to confirmation bias and can be more confident than we ought to be. \n",
    "\n",
    "Be humble, self-reflective, and appreciative that finding the truth is difficult.\n",
    "\n",
    "__TODO__\n",
    "- write notes from the chapter above\n",
    "\n",
    "West, Jevin D.; Bergstrom, Carl T.. Calling Bullshit (p. 264). Penguin Books Ltd. Kindle Edition. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-continuity",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "__Extra__\n",
    "\n",
    "> The problem is the hype, the notion that something magical will emerge if only we can accumulate data on a large enough scale. We just need to be reminded: Big data is not better; it’s just bigger. And it certainly doesn’t speak for itself. In 2014, TED Conferences and the XPrize Foundation announced an award for “the first artificial intelligence to come to this stage and give a TED Talk compelling enough to win a standing ovation from the audience.” People worry that AI has surpassed humans, but we doubt AI will claim this award anytime soon. One might think that the TED brand of bullshit is just a cocktail of sound-bite science, management-speak, and techno-optimism. But it’s not so easy. You have to stir these elements together just right, and you have to sound like you believe them. For the foreseeable future, computers won’t be able to make the grade. Humans are far better bullshitters.<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-garbage",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What next?\n",
    "\n",
    "- If you want more deep learning, learn the keras api for Tensorflow 2.0 or PyTorch.\n",
    "- Once your happy with `scikit-learn` you may want to look at some related python projects: https://scikit-learn.org/stable/related_projects.html#related-projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-record",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Recommended Lectures\n",
    "\n",
    "__(\"Guest\" Lectures in the age of COVID)__\n",
    "- [Calling Bullshit 5.1: Big Data](https://www.youtube.com/watch?v=FLKzmswqF7E&list=PLPnZfvKID1Sje5jWxt-4CSZD7bUI4gSPS&index=23)\n",
    "- [Calling Bullshit 5.2: Garbage In, Garbage Out](https://www.youtube.com/watch?v=pcmUdXIJQ74&list=PLPnZfvKID1Sje5jWxt-4CSZD7bUI4gSPS&index=24)\n",
    "- [Calling Bullshit 5.3: Big Data Hubris](https://www.youtube.com/watch?v=X0XqnAqvyIk&list=PLPnZfvKID1Sje5jWxt-4CSZD7bUI4gSPS&index=25)\n",
    "- [Calling Bullshit 5.4: Overfitting](https://www.youtube.com/watch?v=pDyB_ufVyIw&list=PLPnZfvKID1Sje5jWxt-4CSZD7bUI4gSPS&index=26)\n",
    "- [Calling Bullshit 5.5: Criminal Machine Learning](https://www.youtube.com/watch?v=rga2-d1oi30&list=PLPnZfvKID1Sje5jWxt-4CSZD7bUI4gSPS&index=27)\n",
    "- [Calling Bullshit 5.6: Algorithmic Ethics](https://www.youtube.com/watch?v=4u6HGaXx90A&list=PLPnZfvKID1Sje5jWxt-4CSZD7bUI4gSPS&index=28)\n",
    "\n",
    "\n",
    "# Recommended Readings\n",
    "\n",
    "__Reading__<sup>1</sup>\n",
    "\n",
    "- danah boyd and Kate Crawford (2011) Six Provocations for Big Data. A Decade in Internet Time: Symposium on the Dynamics of the Internet and Society.\n",
    "- David Lazer et al. (2014) The Parable of Google Flu: Traps in Big Data Analysis. Science 343:1203-1205\n",
    "- Alyin Caliskan et al. (2017) Semantics derived automatically from language corpora contain human-like biases Science 356:183-186\n",
    "- Jevin West (2014) How to improve the use of metrics: learn from game theory. Nature 465:871-872\n",
    "\n",
    "__Supplementary reading__<sup>1</sup>\n",
    "\n",
    "- West, Jevin D.; Bergstrom, Carl T.. Calling Bullshit (p. 41). Penguin Books Ltd.\n",
    "- Cathy O'Neil (2016) Weapons of Math Destruction Crown Press.\n",
    "- Peter Lawrence (2014) The mismeasurement of science. Current Biology 17:R583-585\n",
    "\n",
    "# References\n",
    "1. https://www.callingbullshit.org/syllabus.html#Big\n",
    "2. West, Jevin D.; Bergstrom, Carl T.. Calling Bullshit, Penguin Books Ltd.\n",
    "3. https://mailchimp.com/resources/data-bias-causes-effects/\n",
    "4. https://research.aimultiple.com/ai-bias/\n",
    "5. https://www.nature.com/articles/431525a\n",
    "6. Bergstrom, Carl T., and Lee Alan Dugatkin. Evolution. 2nd edition. New York: W. W. Norton and Co., 2012, 2016.\n",
    "7. https://www.callingbullshit.org/case_studies/case_study_criminal_machine_learning.html\n",
    "8. Wu, X., & Zhang, X. (2016). Automated inference on criminality using face images. arXiv preprint arXiv:1611.04135, 4038-4052.\n",
    "9. Lombroso, Cesare. L’Uomo Delinquente. 1876.\n",
    "10. Ribeiro, M. T., S. Singh, and C. Guestrin. “‘Why Should I Trust You?’ Explaining the Predictions of any Classifier.” Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Francisco, August 2016.\n",
    "11. Ginsberg, J., et al. “Detecting Influenza Epidemics Using Search Engine Query Data.” Nature 457 (2009): 1012–14.\n",
    "12. Lazer, D., Kennedy, R., King, G., & Vespignani, A. (2014). The parable of Google Flu: traps in big data analysis. Science, 343(6176), 1203-1205.\n",
    "13. O'Neil, Cathy. Weapons of Math Destruction (p. 2). Penguin Books Ltd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "expanded-subcommittee",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 1_Big_Data_Black_Boxes_and_Bullshit.ipynb to slides\n",
      "[NbConvertApp] Writing 627200 bytes to 1_Big_Data_Black_Boxes_and_Bullshit.slides.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert 1_Big_Data_Black_Boxes_and_Bullshit.ipynb \\\n",
    "    --to slides \\\n",
    "    --output-dir . \\\n",
    "    --TemplateExporter.exclude_input=True \\\n",
    "    --TemplateExporter.exclude_output_prompt=True \\\n",
    "    --SlidesExporter.reveal_scroll=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-teens",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "__EXTRA NOTES__\n",
    "\n",
    "_\"A new class of algorithms, collectively known as adversarial machine learning, can fashion photorealistic faces of nonexistent people out of whole cloth. The fabricated images are stunningly good. This is a dangerous period for a technology: It is widely available but few people know it’s being used. To raise public awareness, we developed a website called WhichFaceIsReal.com.\"__<sup>2</sup>\n",
    "\n",
    "_\"Technologically, the same artificial intelligence techniques used to detect fake news can be used to get around detectors, leading to an arms race of production and detection that the detectors are unlikely to win.\"_<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-walter",
   "metadata": {},
   "source": [
    "# Weapons of math destruction notes\n",
    "\n",
    "_\"models are, by their very nature, simplifications. No model can include all of the real world’s complexity or the nuance of human communication. Inevitably, some important information gets left out.\"_<sup>13</sup>\n",
    "\n",
    "_\"A model, after all, is nothing more than an abstract representation of some process, be it a baseball game, an oil company’s supply chain, a foreign government’s actions, or a movie theater’s attendance. Whether it’s running in a computer program or in our head, the model takes what we know and uses it to predict responses in various situations.\"_<sup>13</sup>\n",
    "\n",
    "_\"The algorithms would make sure that those deemed losers would remain that way. A lucky minority would gain ever more control over the data economy, raking in outrageous fortunes and convincing themselves all the while that they deserved it.\"_<sup>13</sup>\n",
    "\n",
    "_\"This is how many models start out, with a series of hunches. The process is not scientific and has scant grounding in statistical analysis.\"_<sup>13</sup>\n",
    "\n",
    "_\"The job was to teach the computerized system how to replicate the same procedures that human beings had been following. As I’m sure you can guess, these inputs were the problem. The computer learned from the humans how to discriminate, and it carried out this work with breathtaking efficiency.\"_<sup>13</sup>\n",
    "\n",
    "__TODO__\n",
    "- Continue from chapter 8"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
